{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/trainXX\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/trainXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/kaggle/input/trainXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D,LeakyReLU,Conv2DTranspose\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,)\n",
    "                                   \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(path,\n",
    "                                                target_size=(28,56),\n",
    "                                                class_mode = 'categorical',\n",
    "                                                shuffle=True,color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the discriminator model\n",
    "def define_discriminator(image_shape=(28,28,1,)):\n",
    "    in_image = Input(shape=image_shape)\n",
    "    out_image = Input(shape=image_shape)\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    merged = Concatenate(axis=-1)([in_image, out_image])\n",
    "    \n",
    "    \n",
    "    d = Conv2D(64, (3,3), kernel_initializer=init)(merged)\n",
    "    d= LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(128, (3,3), kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Dropout(0.5)(d)\n",
    "    d = MaxPooling2D(pool_size=2,strides=2)(d)\n",
    "  \n",
    "    d = Conv2D(196, (3,3), kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Dropout(0.5)(d)\n",
    "    d = MaxPooling2D(pool_size=2,strides=2)(d)\n",
    "  \n",
    "    d = Conv2D(256, (3,3), kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Dropout(0.5)(d)\n",
    "    d = MaxPooling2D(pool_size=2,strides=2)(d)\n",
    "  \n",
    "    d = Flatten()(d)\n",
    "    d = Dense(256, activation='relu')(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Dropout(0.5)(d)\n",
    "  \n",
    "    d = Dense(128)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Dropout(0.5)(d)\n",
    "  \n",
    "    d = Dense(64)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Dropout(0.5)(d)\n",
    "    \n",
    "    d = Dense(32)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Dense(1)(d) \n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "  \n",
    "    model = Model([in_image, out_image], patch_out)\n",
    "    print('Compiling Discriminator')\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'], loss_weights=[0.5])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(image_shape=(28,28,1,)):\n",
    "    in_image = Input(shape=image_shape)\n",
    "    g = Conv2D(64, kernel_size=3, activation='relu',padding='same', input_shape=(28,28,1))(in_image)\n",
    "    g = BatchNormalization()(g)\n",
    "    \n",
    "    g = Conv2D(128, kernel_size=3, strides=(2, 2))(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Dropout(0.25)(g)\n",
    "    \n",
    "    g = Conv2D(196, kernel_size=3, strides=(2, 2))(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Dropout(0.25)(g)\n",
    "    \n",
    "    g = Conv2D(256, kernel_size=3, strides=(2, 2))(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Dropout(0.25)(g)\n",
    "    \n",
    "    g = Conv2D(512, kernel_size=2, strides=(2, 2))(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Dropout(0.25)(g)\n",
    "    \n",
    "    g = Conv2DTranspose(512, kernel_size=3, strides=(2, 2))(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Dropout(0.25)(g)\n",
    "    \n",
    "    g = Conv2DTranspose(256, kernel_size=2, strides=(2, 2))(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Dropout(0.25)(g)\n",
    "    \n",
    "    g = Conv2DTranspose(128, kernel_size=3, strides=(2, 2))(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Dropout(0.25)(g)\n",
    "    \n",
    "    g = Conv2DTranspose(1, kernel_size=4, strides=(2, 2))(g)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    model = Model(in_image, out_image)\n",
    "    print('Compiling generator')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Discriminator\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 2)    0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 26, 26, 64)   1216        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 26, 26, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 24, 24, 128)  73856       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 24, 24, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 24, 24, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 24, 24, 128)  0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 128)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 196)  225988      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10, 10, 196)  784         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 10, 10, 196)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10, 10, 196)  0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 196)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 256)    451840      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 3, 3, 256)    1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 3, 3, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 3, 3, 256)    0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 256)    0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 128)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64)           256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 64)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32)           128         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 32)           0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            33          leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 866,197\n",
      "Trainable params: 864,077\n",
      "Non-trainable params: 2,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = define_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling generator\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 196)         225988    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 6, 6, 196)         784       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 6, 6, 196)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 196)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 256)         451840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1, 1, 512)         524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 6, 6, 256)         524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 13, 13, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         2049      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 4,466,773\n",
      "Trainable params: 4,462,669\n",
      "Non-trainable params: 4,104\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = define_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model, image_shape=(28,28,1,)):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # define the source image\n",
    "    in_src = Input(shape=image_shape)\n",
    "    # connect the source image to the generator input\n",
    "    gen_out = g_model(in_src)\n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model(in_src, [dis_out, gen_out])\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, image_hand, patch_shape=1):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(image_hand)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = np.zeros((len(X), patch_shape))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generat_real_samples( patch_shape=1):\n",
    "    X,y = training_set.next()\n",
    "    real_print,real_hand = X[:,:,:28],X[:,:,28:]\n",
    "    real_hand = np.reshape(real_hand,[-1, 28, 28, 1])\n",
    "    real_print = np.reshape(real_print,[-1, 28, 28, 1])\n",
    "    real_label = np.ones((len(X), patch_shape))\n",
    "    return [real_hand,real_print],real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = training_set.n//training_set.batch_size\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model = define_gan(generator,discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fake_hand' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d864fd4f5239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0md_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_hand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal_print\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#update discriminator for fake sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0md_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfake_hand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal_print\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# update the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_hand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreal_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_print\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fake_hand' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(I):\n",
    "    #generating real sample\n",
    "    [real_hand,real_print],real_label = generat_real_samples()\n",
    "    #generating fake sample\n",
    "    fake_print,fake_label = generate_fake_samples(generator,real_hand)\n",
    "    #update discriminator for real sample\n",
    "    d_loss1 = discriminator.train_on_batch([real_hand,real_print,], real_label)\n",
    "    #update discriminator for fake sample\n",
    "    d_loss2 = discriminator.train_on_batch([fake_print,real_print,], fake_label)\n",
    "    # update the generator\n",
    "    g_loss, _, _ = gan_model.train_on_batch(real_hand, [real_label, real_print])\n",
    "    #print performance\n",
    "    print(\"epoch {}: real_loss: {}---fake_loss: {}---GAN_LOSS: {}\".format(i+1, d_loss1,d_loss2,g_loss))\n",
    "    if i % 10 == 0:\n",
    "        #filename = '/GAN/model_%06d' % (i+1)\n",
    "        #g_model.save(filename+'gan.h5')\n",
    "        #generator.save(filename+'generator.h5')\n",
    "        #discriminator.save(filename+'discriminator.h5')\n",
    "        a = np.random.randint(1,32)\n",
    "        i = real_print[a]\n",
    "        j = np.reshape(i,(28,28))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(j,cmap='gray')\n",
    "        i = real_hand[a]\n",
    "        j = np.reshape(i,(28,28))\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(j,cmap='gray')\n",
    "        i = fake_print[a]\n",
    "        j = np.reshape(i,(28,28))\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(j,cmap='gray')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
